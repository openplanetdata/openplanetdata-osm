name: Planet GeoParquet

on:
  workflow_dispatch:
  workflow_run:
    workflows: ["Build & Publish CRCP Snapshots", "Planet GeoDesk v1"]
    types: [completed]
    branches: [main]

env:
  OHSOME_JAR_PATH: ohsome-planet/ohsome-planet-cli/target/ohsome-planet.jar

jobs:
  geoparquet:
    runs-on: self-hosted
    timeout-minutes: 300

    outputs:
      tag: ${{ steps.date.outputs.tag }}

    steps:
      - name: Show runner architecture
        run: echo "arch = ${{ runner.arch }}"

      - name: Set date tag
        id: date
        uses: openplanetdata/actions/set-date-tag@main

      - name: Install system dependencies
        uses: openplanetdata/actions/install-packages@main
        with:
          packages: jq unzip

      - uses: actions/setup-java@v5
        with:
          distribution: temurin
          java-version: 25

      - name: Get latest DuckDB release tag
        id: get_duckdb_tag
        run: |
          for i in 1 2 3; do
            RESPONSE=$(curl -s https://api.github.com/repos/duckdb/duckdb/releases/latest)
            TAG=$(echo "$RESPONSE" | jq -r .tag_name)
            if [ -n "$TAG" ] && [ "$TAG" != "null" ]; then
              echo "tag=$TAG" >>"$GITHUB_OUTPUT"
              echo "Successfully fetched DuckDB release tag: $TAG"
              exit 0
            fi
            echo "::warning::Attempt $i failed to fetch DuckDB release tag, retrying..."
            sleep 2
          done
          echo "::error::Failed to fetch DuckDB release tag after 3 attempts"
          echo "Last API response: $RESPONSE"
          exit 1

      - name: Install latest DuckDB cli
        run: |
          case "${{ runner.arch }}" in
            X64)   system_config="linux-amd64" ;;
            ARM64) system_config="linux-arm64" ;;
            *) echo "Unsupported architecture: ${{ runner.arch }}"; exit 1 ;;
          esac
          wget https://github.com/duckdb/duckdb/releases/download/${{ steps.get_duckdb_tag.outputs.tag }}/duckdb_cli-$system_config.zip
          unzip -o duckdb_cli-$system_config.zip
          chmod a+x ./duckdb

      - name: Get latest ohsome-planet release tag
        id: get_ohsome_tag
        run: |
          for i in 1 2 3; do
            RESPONSE=$(curl -s https://api.github.com/repos/GIScience/ohsome-planet/releases/latest)
            TAG=$(echo "$RESPONSE" | jq -r .tag_name)
            if [ -n "$TAG" ] && [ "$TAG" != "null" ]; then
              echo "tag=$TAG" >>"$GITHUB_OUTPUT"
              echo "Successfully fetched ohsome-planet release tag: $TAG"
              exit 0
            fi
            echo "::warning::Attempt $i failed to fetch ohsome-planet release tag, retrying..."
            sleep 2
          done
          echo "::error::Failed to fetch ohsome-planet release tag after 3 attempts"
          echo "Last API response: $RESPONSE"
          exit 1

      - name: Checkout ohsome-planet
        uses: actions/checkout@v5
        with:
          repository: GIScience/ohsome-planet
          ref: ${{ steps.get_ohsome_tag.outputs.tag }}
          path: ohsome-planet
          submodules: recursive

      - name: Build ohsome-planet JAR
        run: |
          cd ohsome-planet
          ./mvnw -q clean package -DskipTests
          echo "::group::Directory listing (depth 2)"
          find . -maxdepth 2 -type d | sort
          echo "::endgroup::"

          if [ -d ohsome-planet-cli/target ]; then
            echo "::group::ohsome-planet-cli/target contents"
            ls -al ohsome-planet-cli/target
            echo "::endgroup::"
          else
            echo "::warning::ohsome-planet-cli/target directory not found"
          fi

          echo "::group::Discovered jar files"
          find . -name "*.jar" -type f | sort
          echo "::endgroup::"

      - name: Download latest published PBF
        uses: openplanetdata/actions/download@main
        with:
          remote_path: osm/planet/pbf/planet-latest.osm.pbf

      - name: Rename downloaded PBF
        run: mv planet-latest.osm.pbf "planet-${{ steps.date.outputs.tag }}.osm.pbf"

      - name: Build GeoParquet with ohsome-planet from PBF
        env:
          TAG: ${{ steps.date.outputs.tag }}
        run: |
          PBF="planet-${TAG}.osm.pbf"
          OUT_DIR="ohsome-${TAG}"

          # Remove old ohsome folders from previous days
          echo "::group::Cleaning old ohsome folders"
          for dir in ohsome-*; do
            if [ -d "$dir" ] && [ "$dir" != "$OUT_DIR" ]; then
              if [ "$dir" = "ohsome-planet" ]; then
                echo "Skipping source directory: $dir"
                continue
              fi
              echo "Removing old folder: $dir"
              rm -rf "$dir"
            fi
          done
          echo "::endgroup::"

          # Check if today's ohsome output already exists
          if [ -d "$OUT_DIR" ] && [ -d "$OUT_DIR/contributions/latest" ]; then
            echo "::notice::Found existing ohsome output for today ($OUT_DIR), skipping 2+ hour build"
            echo "::group::Cached files"
            find "$OUT_DIR" -print | sort
            echo "::endgroup::"
          else
            echo "::notice::Building ohsome output for today ($OUT_DIR)"

            # Ensure clean output directory
            rm -rf "$OUT_DIR"

            time java -Xms96g -Xmx96g -jar "${{ env.OHSOME_JAR_PATH }}" contributions \
                 --pbf "$PBF" --data "$OUT_DIR"

            # Check if ohsome-planet completed successfully
            if [ $? -ne 0 ]; then
              echo "::error::ohsome-planet failed to complete"
              exit 1
            fi

            # list everything just produced
            echo "::group::Produced files"
            find "$OUT_DIR" -print | sort
            echo "::endgroup::"
          fi

          # Validate parquet files before processing with DuckDB
          # Force full scan with MAX(osm_id) to trigger decompression of all row groups
          # LIMIT 1 only reads first row group and misses corruption elsewhere
          echo "::group::Validating parquet files"
          VALIDATION_FAILED=0
          for parquet_file in "$OUT_DIR"/contributions/latest/*.parquet; do
            if [ -f "$parquet_file" ]; then
              echo "Validating: $parquet_file"
              if ! ./duckdb -c "SELECT MAX(osm_id) FROM '$parquet_file'" > /dev/null 2>&1; then
                echo "::error::Corrupted parquet file detected: $parquet_file"
                VALIDATION_FAILED=1
              fi
            fi
          done

          if [ $VALIDATION_FAILED -eq 1 ]; then
            echo "::error::One or more parquet files failed validation"
            echo "::notice::Removing corrupted cached output to trigger rebuild on next run"
            rm -rf "$OUT_DIR"
            exit 1
          fi
          echo "All parquet files validated successfully"
          echo "::endgroup::"

          # Use workspace directory for temp files (not /tmp which may be tmpfs/RAM)
          DUCKDB_TEMP_DIR="${PWD}/.duckdb-temp"
          mkdir -p "$DUCKDB_TEMP_DIR"

          ./duckdb -c "
              INSTALL 'spatial'; LOAD 'spatial';
              SET temp_directory='${DUCKDB_TEMP_DIR}';
              SET preserve_insertion_order=false;

              COPY (
                  SELECT
                    osm_type::ENUM ('node', 'way', 'relation') AS osm_type,
                    osm_id,
                    tags,
                    bbox,
                    geometry
                  FROM '${OUT_DIR}/contributions/latest/*.parquet'
                  ORDER BY bbox.xmin, bbox.ymin, bbox.xmax, bbox.ymax
              ) TO 'planet-${TAG}.osm.parquet' (
                  FORMAT PARQUET,
                  CODEC 'zstd',
                  COMPRESSION_LEVEL 13,
                  PARQUET_VERSION v2
              );
          "

          # Cleanup temp directory
          rm -rf "$DUCKDB_TEMP_DIR"

      - name: Create metadata
        id: create_meta
        uses: openplanetdata/actions/create-metadata@main
        with:
          file: planet-${{ steps.date.outputs.tag }}.osm.parquet
          remote_filename: planet-latest.osm.parquet
          remote_path: /osm/planet/geoparquet
          remote_version: 1
          tags: |
            geoparquet
            openstreetmap
            public

      - name: Upload to R2
        uses: openplanetdata/actions/upload@main
        env:
          RCLONE_CONFIG_DATA: ${{ secrets.RCLONE_CONFIG_DATA }}
        with:
          file: planet-${{ steps.date.outputs.tag }}.osm.parquet
          remote_filename: planet-latest.osm.parquet
          remote_path: /osm/planet/geoparquet
          remote_version: 1

      - name: Cleanup downloaded files
        if: always()
        uses: openplanetdata/actions/cleanup-downloads@main

      - name: Cleanup generated files
        if: always()
        env:
          TAG: ${{ steps.date.outputs.tag }}
        run: |
          rm -f duckdb duckdb_cli-*.zip
          rm -f planet-*.osm.parquet planet-*.osm.parquet.{sha256,metadata}
          rm -rf ohsome-planet
          rm -rf .duckdb-temp
          find . -name "*.jar" -delete
          find /tmp -name "tmp.*" -user "$USER" -delete 2>/dev/null || true
          # Remove old PBF files and indexes, keep today's for caching
          for f in planet-*.osm.pbf; do
            [ -f "$f" ] && [ "$f" != "planet-${TAG}.osm.pbf" ] && rm -f "$f" || true
          done
          for d in planet-*.osm-indexes; do
            [ -d "$d" ] && [ "$d" != "planet-${TAG}.osm-indexes" ] && rm -rf "$d" || true
          done
          # Keep ohsome-* output folders for day-based caching (cleaned up on next day's run)
