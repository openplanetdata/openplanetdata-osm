name: Extract Boundary (Reusable)

on:
  workflow_call:
    inputs:
      entity_code:
        description: 'Code for the entity (e.g., FR for France, africa for Africa)'
        required: true
        type: string
      entity_name:
        description: 'Human-readable name of the entity'
        required: true
        type: string
      entity_type:
        description: 'Type of entity (country, continent, region, etc.)'
        required: true
        type: string
      osm_query:
        description: 'OSM query to find the boundary relation (e.g., a["ISO3166-1:alpha2"="FR"])'
        required: true
        type: string
      remote_path:
        description: 'Remote path for upload (e.g., /osm/boundaries/countries)'
        required: true
        type: string
      remote_version:
        description: 'Remote version number'
        required: false
        type: string
        default: '1'
      tags:
        description: 'Newline-separated tags for metadata'
        required: false
        type: string
        default: |
          boundary
          openstreetmap
          public
      cleanup_planet_files:
        description: 'Whether to cleanup planet files after processing (set to false to reuse across multiple countries)'
        required: false
        type: boolean
        default: false
      has_coastline:
        description: 'Whether this entity has a coastline (false for landlocked countries)'
        required: false
        type: boolean
        default: true

    outputs:
      failure_reason:
        description: 'Reason for failure if extraction failed'
        value: ${{ jobs.extract.outputs.failure_reason }}
      feature_count:
        description: 'Number of features in the output'
        value: ${{ jobs.extract.outputs.feature_count }}
      output_file:
        description: 'Path to the generated GeoJSON file'
        value: ${{ jobs.extract.outputs.output_file }}
      parquet_file:
        description: 'Path to the generated GeoParquet file'
        value: ${{ jobs.extract.outputs.parquet_file }}
      success:
        description: 'Whether the extraction succeeded (true/false)'
        value: ${{ jobs.extract.outputs.success }}

    secrets:
      RCLONE_CONFIG_DATA:
        description: 'Rclone configuration for R2 access'
        required: true

jobs:
  extract:
    runs-on: self-hosted
    timeout-minutes: 60

    outputs:
      failure_reason: ${{ steps.extract.outputs.failure_reason }}
      feature_count: ${{ steps.extract.outputs.feature_count }}
      output_file: ${{ steps.extract.outputs.output_file }}
      parquet_file: ${{ steps.extract.outputs.parquet_file }}
      success: ${{ steps.extract.outputs.success }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set date tag
        id: date
        uses: openplanetdata/actions/set-date-tag@main

      - name: Install GOL
        uses: openplanetdata/actions/install-gol@main
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          version: 2

      - name: Install system dependencies
        shell: bash
        run: |
          need_install() { ! command -v "$1" &>/dev/null; }

          # Detect OS and package manager
          if command -v apt-get &>/dev/null; then
            # Ubuntu/Debian
            PKG_MANAGER="apt-get"
            PKGS=()

            need_install ogr2ogr && PKGS+=(gdal-bin)
            need_install jq && PKGS+=(jq)

            if [ ${#PKGS[@]} -gt 0 ]; then
              # Remove duplicates
              PKGS=($(printf '%s\n' "${PKGS[@]}" | sort -u))
              sudo apt-get update -qq
              sudo apt-get install -y "${PKGS[@]}"
            fi
          elif command -v dnf &>/dev/null; then
            # Fedora/RHEL/CentOS
            PKG_MANAGER="dnf"
            PKGS=()

            need_install ogr2ogr && PKGS+=(gdal)
            need_install jq && PKGS+=(jq)

            if [ ${#PKGS[@]} -gt 0 ]; then
              # Remove duplicates
              PKGS=($(printf '%s\n' "${PKGS[@]}" | sort -u))
              sudo dnf -y install "${PKGS[@]}"
            fi
          else
            echo "⚠️ Unsupported package manager. Please install manually: gdal, jq"
            exit 1
          fi

          # Verify installations
          echo "Verifying installations..."
          command -v gol && gol --version
          command -v ogr2ogr && ogr2ogr --version
          command -v jq && jq --version

      - name: Check for existing planet files
        id: check_files
        run: |
          TAG="${{ steps.date.outputs.tag }}"

          # Check for GOL file (dated or latest)
          if [ -f "planet-${TAG}.osm.gol" ]; then
            echo "gol_exists=true" >> $GITHUB_OUTPUT
            echo "✓ Found existing planet-${TAG}.osm.gol"
          elif [ -f "planet-latest.osm.gol" ]; then
            mv planet-latest.osm.gol "planet-${TAG}.osm.gol"
            echo "gol_exists=true" >> $GITHUB_OUTPUT
            echo "✓ Found and renamed planet-latest.osm.gol to planet-${TAG}.osm.gol"
          else
            echo "gol_exists=false" >> $GITHUB_OUTPUT
            echo "→ Need to download planet GOL"
          fi

          # Check for coastline file (dated or latest)
          if [ -f "coastline-${TAG}.gpkg" ]; then
            echo "coastline_exists=true" >> $GITHUB_OUTPUT
            echo "✓ Found existing coastline-${TAG}.gpkg"
          elif [ -f "planet-coastline-latest.osm.gpkg" ]; then
            mv planet-coastline-latest.osm.gpkg "coastline-${TAG}.gpkg"
            echo "coastline_exists=true" >> $GITHUB_OUTPUT
            echo "✓ Found and renamed planet-coastline-latest.osm.gpkg to coastline-${TAG}.gpkg"
          else
            echo "coastline_exists=false" >> $GITHUB_OUTPUT
            echo "→ Need to download coastline GPKG"
          fi

      - name: Download planet GOB
        if: steps.check_files.outputs.gol_exists == 'false'
        uses: openplanetdata/actions/download@main
        with:
          remote_path: /osm/planet/gob/v2/planet-latest.osm.gob

      - name: Convert GOB to GOL
        if: steps.check_files.outputs.gol_exists == 'false'
        run: |
          echo "Converting GOB to GOL..."
          gol load planet-latest.osm.gol planet-latest.osm.gob
          echo "✓ Conversion complete"
          rm planet-latest.osm.gob
          ls -alh planet-latest.osm.gol

      - name: Download coastline GPKG
        if: steps.check_files.outputs.coastline_exists == 'false'
        uses: openplanetdata/actions/download@main
        with:
          remote_path: /osm/planet/coastline/v1/planet-coastline-latest.osm.gpkg

      - name: Rename downloaded files
        run: |
          TAG="${{ steps.date.outputs.tag }}"
          [ -f planet-latest.osm.gol ] && mv planet-latest.osm.gol "planet-${TAG}.osm.gol"
          [ -f planet-coastline-latest.osm.gpkg ] && mv planet-coastline-latest.osm.gpkg "coastline-${TAG}.gpkg"
          ls -alh

      - name: Extract boundary
        id: extract
        shell: bash
        run: |
          set +e  # Don't exit on error, we'll handle it

          ENTITY_TYPE="${{ inputs.entity_type }}"
          ENTITY_CODE="${{ inputs.entity_code }}"
          ENTITY_NAME="${{ inputs.entity_name }}"
          OSM_QUERY='${{ inputs.osm_query }}'
          TAG="${{ steps.date.outputs.tag }}"

          PLANET_GOL="planet-${TAG}.osm.gol"
          COASTLINE_DB="coastline-${TAG}.gpkg"
          OUTPUT_DIR="boundaries/${ENTITY_TYPE}s"
          OUTPUT_FILE="${ENTITY_CODE}.boundary.geojson"
          TMPDIR="boundaries/tmp/${ENTITY_CODE}"
          LOGFILE="boundaries/logs/${ENTITY_CODE}.log"

          # Create directories
          mkdir -p "$OUTPUT_DIR" "$TMPDIR" "boundaries/logs"

          # Redirect output to log
          exec 1> >(tee -a "$LOGFILE")
          exec 2>&1

          echo "=========================================="
          echo "Extracting: $ENTITY_CODE - $ENTITY_NAME"
          echo "Type: $ENTITY_TYPE"
          echo "Query: $OSM_QUERY"
          echo "Started at: $(date -u +%Y-%m-%d_%H:%M:%S)"
          echo "=========================================="

          # Step 1: Extract boundary using gol query
          echo "→ Step 1/4: Extracting boundary with gol query..."
          if ! gol query "$PLANET_GOL" "$OSM_QUERY" -f geojson > "$TMPDIR/${ENTITY_CODE}_raw.geojson"; then
            echo "❌ Failed to extract boundary with gol query" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to extract boundary with gol query" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 1
          fi

          # Validate raw extraction
          FEATURE_COUNT=$(jq '.features | length' "$TMPDIR/${ENTITY_CODE}_raw.geojson" 2>/dev/null || echo "0")
          if [ "$FEATURE_COUNT" -eq 0 ]; then
            echo "❌ No features found in gol query result" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=No features found in gol query result" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 2
          fi
          echo "  ✓ Extracted boundary with $FEATURE_COUNT feature(s)"

          # Step 2: Clip with coastline if coastal entity
          HAS_COASTLINE="${{ inputs.has_coastline }}"

          if [ "$HAS_COASTLINE" = "true" ]; then
            echo "→ Step 2/4: Clipping with coastline data..."
            if ogr2ogr -f GeoJSON "$TMPDIR/${ENTITY_CODE}_clipped.geojson" "$COASTLINE_DB" land_polygons \
              -clipsrc "$TMPDIR/${ENTITY_CODE}_raw.geojson" -q 2>/dev/null; then
              echo "  ✓ Clipped with coastline data"
              WORKING_FILE="$TMPDIR/${ENTITY_CODE}_clipped.geojson"
            else
              echo "  ⚠️ Coastline clipping failed, using raw boundary"
              WORKING_FILE="$TMPDIR/${ENTITY_CODE}_raw.geojson"
            fi
          else
            echo "→ Step 2/4: Skipping coastline clipping (landlocked)"
            WORKING_FILE="$TMPDIR/${ENTITY_CODE}_raw.geojson"
          fi

          # Step 3: Dissolve geometry (merge multiple polygons)
          echo "→ Step 3/4: Dissolving geometry..."
          if ! ogr2ogr -f GeoJSON "$TMPDIR/${ENTITY_CODE}_dissolved.geojson" "$WORKING_FILE" -dialect sqlite \
            -sql "SELECT ST_CollectionExtract(ST_UnaryUnion(ST_Collect(geometry)), 3) AS geometry FROM land_polygons" -q; then
            echo "❌ Failed to dissolve geometry" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to dissolve geometry" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 3
          fi
          echo "  ✓ Dissolved geometry"

          # Step 4: Copy dissolved geometry to final output
          echo "→ Step 4/4: Creating final output..."
          cp "$TMPDIR/${ENTITY_CODE}_dissolved.geojson" "$OUTPUT_DIR/$OUTPUT_FILE"
          echo "  ✓ Created final output"

          # Validate the output
          echo "→ Validating output..."
          if [ ! -f "$OUTPUT_DIR/$OUTPUT_FILE" ]; then
            echo "❌ Output file not created" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Output file not created" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 4
          fi

          FINAL_FEATURE_COUNT=$(jq '.features | length' "$OUTPUT_DIR/$OUTPUT_FILE" 2>/dev/null || echo "0")
          if [ "$FINAL_FEATURE_COUNT" -eq 0 ]; then
            echo "❌ No features in final output" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=No features in output" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            rm -rf "$TMPDIR"
            exit 5
          fi
          echo "  ✓ Output validated: $FINAL_FEATURE_COUNT feature(s)"

          # Clean up temp files
          rm -rf "$TMPDIR"

          # Convert GeoJSON to GeoParquet
          echo "→ Converting to GeoParquet..."
          PARQUET_FILE="${OUTPUT_DIR}/${ENTITY_CODE}.boundary.parquet"
          if ! ogr2ogr -f Parquet "$PARQUET_FILE" "$OUTPUT_DIR/$OUTPUT_FILE" \
            --config OGR_GEOJSON_MAX_OBJ_SIZE 0 \
            -lco COMPRESSION=ZSTD \
            -lco GEOMETRY_ENCODING=GEOARROW \
            -lco ROW_GROUP_SIZE=65536; then
            echo "❌ Failed to convert to GeoParquet" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to convert to GeoParquet" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            exit 6
          fi
          echo "  ✓ GeoParquet created: $(basename $PARQUET_FILE)"

          ls -alh .

          # Set outputs
          echo "success=true" >> $GITHUB_OUTPUT
          echo "output_file=$OUTPUT_DIR/$OUTPUT_FILE" >> $GITHUB_OUTPUT
          echo "parquet_file=$PARQUET_FILE" >> $GITHUB_OUTPUT
          echo "feature_count=$FINAL_FEATURE_COUNT" >> $GITHUB_OUTPUT

          echo "✅ $OUTPUT_FILE created successfully with $FINAL_FEATURE_COUNT feature(s)"
          echo "✅ $(basename $PARQUET_FILE) created successfully"
          echo "Finished at: $(date -u +%Y-%m-%d_%H:%M:%S)"

      - name: Create metadata
        if: steps.extract.outputs.success == 'true'
        uses: openplanetdata/actions/create-metadata@main
        with:
          file: ${{ steps.extract.outputs.output_file }}
          remote_filename: ${{ inputs.entity_code }}.boundary.geojson
          remote_path: ${{ inputs.remote_path }}
          remote_version: ${{ inputs.remote_version }}
          tags: ${{ inputs.tags }}

      - name: Upload to R2
        if: steps.extract.outputs.success == 'true'
        uses: openplanetdata/actions/upload@main
        env:
          RCLONE_CONFIG_DATA: ${{ secrets.RCLONE_CONFIG_DATA }}
        with:
          file: ${{ steps.extract.outputs.output_file }}
          remote_filename: ${{ inputs.entity_code }}.boundary.geojson
          remote_path: ${{ inputs.remote_path }}
          remote_version: ${{ inputs.remote_version }}

      - name: Create metadata for Parquet
        if: steps.extract.outputs.success == 'true'
        uses: openplanetdata/actions/create-metadata@main
        with:
          file: ${{ steps.extract.outputs.parquet_file }}
          remote_filename: ${{ inputs.entity_code }}.boundary.parquet
          remote_path: ${{ inputs.remote_path }}
          remote_version: ${{ inputs.remote_version }}
          tags: ${{ inputs.tags }}

      - name: Upload Parquet to R2
        if: steps.extract.outputs.success == 'true'
        uses: openplanetdata/actions/upload@main
        env:
          RCLONE_CONFIG_DATA: ${{ secrets.RCLONE_CONFIG_DATA }}
        with:
          file: ${{ steps.extract.outputs.parquet_file }}
          remote_filename: ${{ inputs.entity_code }}.boundary.parquet
          remote_path: ${{ inputs.remote_path }}
          remote_version: ${{ inputs.remote_version }}

      - name: Cleanup generated files
        if: always()
        run: |
          # Always cleanup metadata and temp files
          rm -f boundaries/${{ inputs.entity_type }}s/*.boundary.geojson.{sha256,metadata}
          rm -f boundaries/${{ inputs.entity_type }}s/*.boundary.parquet.{sha256,metadata}
          rm -rf boundaries/tmp boundaries/logs

      - name: Cleanup planet files
        if: always() && inputs.cleanup_planet_files == true
        run: |
          echo "Cleaning up planet files..."
          rm -f planet-*.osm.gol coastline-*.gpkg
