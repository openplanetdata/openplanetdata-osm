name: Extract Boundary (Reusable)

on:
  workflow_call:
    inputs:
      entity_code:
        description: 'Code for the entity (e.g., FR for France, africa for Africa)'
        required: true
        type: string
      entity_name:
        description: 'Human-readable name of the entity'
        required: true
        type: string
      entity_type:
        description: 'Type of entity (country, continent, region, etc.)'
        required: true
        type: string
      osm_query:
        description: 'OSM query to find the boundary relation (e.g., a["ISO3166-1:alpha2"="FR"])'
        required: true
        type: string
      remote_path:
        description: 'Remote path for upload (e.g., /osm/boundaries/countries)'
        required: true
        type: string
      remote_version:
        description: 'Remote version number'
        required: false
        type: string
        default: '1'
      tags:
        description: 'Newline-separated tags for metadata'
        required: false
        type: string
        default: |
          boundary
          openstreetmap
          public
      cleanup_planet_files:
        description: 'Whether to cleanup planet files after processing (set to false to reuse across multiple countries)'
        required: false
        type: boolean
        default: false
      has_coastline:
        description: 'Whether this entity has a coastline (false for landlocked countries)'
        required: false
        type: boolean
        default: true

    outputs:
      failure_reason:
        description: 'Reason for failure if extraction failed'
        value: ${{ jobs.extract.outputs.failure_reason }}
      feature_count:
        description: 'Number of features in the output'
        value: ${{ jobs.extract.outputs.feature_count }}
      output_file:
        description: 'Path to the generated GeoJSON file'
        value: ${{ jobs.extract.outputs.output_file }}
      parquet_file:
        description: 'Path to the generated GeoParquet file'
        value: ${{ jobs.extract.outputs.parquet_file }}
      success:
        description: 'Whether the extraction succeeded (true/false)'
        value: ${{ jobs.extract.outputs.success }}

    secrets:
      RCLONE_CONFIG_DATA:
        description: 'Rclone configuration for R2 access'
        required: true

jobs:
  extract:
    runs-on: self-hosted
    timeout-minutes: 60

    outputs:
      failure_reason: ${{ steps.extract.outputs.failure_reason }}
      feature_count: ${{ steps.extract.outputs.feature_count }}
      output_file: ${{ steps.extract.outputs.output_file }}
      parquet_file: ${{ steps.extract.outputs.parquet_file }}
      success: ${{ steps.extract.outputs.success }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set date tag
        id: date
        uses: openplanetdata/actions/set-date-tag@main

      - name: Install system dependencies
        shell: bash
        run: |
          need_install() { ! command -v "$1" &>/dev/null; }

          # Detect OS and package manager
          if command -v apt-get &>/dev/null; then
            # Ubuntu/Debian
            PKG_MANAGER="apt-get"
            PKGS=()

            need_install ogr2ogr && PKGS+=(gdal-bin)
            need_install ogrinfo && PKGS+=(gdal-bin)
            need_install jq && PKGS+=(jq)

            if [ ${#PKGS[@]} -gt 0 ]; then
              # Remove duplicates
              PKGS=($(printf '%s\n' "${PKGS[@]}" | sort -u))
              sudo apt-get update -qq
              sudo apt-get install -y "${PKGS[@]}"
            fi
          elif command -v dnf &>/dev/null; then
            # Fedora/RHEL/CentOS
            PKG_MANAGER="dnf"
            PKGS=()

            need_install ogr2ogr && PKGS+=(gdal)
            need_install ogrinfo && PKGS+=(gdal)
            need_install jq && PKGS+=(jq)

            if [ ${#PKGS[@]} -gt 0 ]; then
              # Remove duplicates
              PKGS=($(printf '%s\n' "${PKGS[@]}" | sort -u))
              sudo dnf -y install "${PKGS[@]}"
            fi
          else
            echo "⚠️ Unsupported package manager. Please install manually: gdal, jq"
            exit 1
          fi

          # Verify installations
          echo "Verifying installations..."
          command -v ogr2ogr && ogr2ogr --version
          command -v jq && jq --version

      - name: Install Python dependencies
        shell: bash
        run: |
          python3 -m pip install --user pyproj

      - name: Check for existing planet files
        id: check_files
        run: |
          TAG="${{ steps.date.outputs.tag }}"

          if [ -f "planet-${TAG}.osm.pbf" ]; then
            echo "pbf_exists=true" >> $GITHUB_OUTPUT
            echo "✓ Found existing planet-${TAG}.osm.pbf"
          else
            echo "pbf_exists=false" >> $GITHUB_OUTPUT
            echo "→ Need to download planet-${TAG}.osm.pbf"
          fi

          if [ -f "coastline-${TAG}.gpkg" ]; then
            echo "coastline_exists=true" >> $GITHUB_OUTPUT
            echo "✓ Found existing coastline-${TAG}.gpkg"
          else
            echo "coastline_exists=false" >> $GITHUB_OUTPUT
            echo "→ Need to download coastline-${TAG}.gpkg"
          fi

      - name: Download planet PBF
        if: steps.check_files.outputs.pbf_exists == 'false'
        uses: openplanetdata/actions/download@main
        with:
          remote_path: osm/planet/pbf/planet-latest.osm.pbf

      - name: Download coastline GPKG
        if: steps.check_files.outputs.coastline_exists == 'false'
        uses: openplanetdata/actions/download@main
        with:
          remote_path: /osm/planet/coastline/v1/planet-coastline-latest.osm.gpkg

      - name: Rename downloaded files
        run: |
          TAG="${{ steps.date.outputs.tag }}"
          [ -f planet-latest.osm.pbf ] && mv planet-latest.osm.pbf "planet-${TAG}.osm.pbf"
          [ -f planet-coastline-latest.osm.gpkg ] && mv planet-coastline-latest.osm.gpkg "coastline-${TAG}.gpkg"
          ls -alh

      - name: Extract boundary
        id: extract
        shell: bash
        run: |
          set +e  # Don't exit on error, we'll handle it

          ENTITY_TYPE="${{ inputs.entity_type }}"
          ENTITY_CODE="${{ inputs.entity_code }}"
          ENTITY_NAME="${{ inputs.entity_name }}"
          OSM_QUERY='${{ inputs.osm_query }}'
          TAG="${{ steps.date.outputs.tag }}"

          PLANET_PBF="planet-${TAG}.osm.pbf"
          COASTLINE_DB="coastline-${TAG}.gpkg"
          OUTPUT_DIR="boundaries/${ENTITY_TYPE}s"
          OUTPUT_FILE="${ENTITY_CODE}.boundary.geojson"
          TMPDIR="boundaries/tmp/${ENTITY_CODE}"
          LOGFILE="boundaries/logs/${ENTITY_CODE}.log"

          # Create directories
          mkdir -p "$OUTPUT_DIR" "$TMPDIR" "boundaries/logs"

          # Redirect output to log
          exec 1> >(tee -a "$LOGFILE")
          exec 2>&1

          echo "=========================================="
          echo "Extracting: $ENTITY_CODE - $ENTITY_NAME"
          echo "Type: $ENTITY_TYPE"
          echo "Query: $OSM_QUERY"
          echo "Started at: $(date -u +%Y-%m-%d_%H:%M:%S)"
          echo "=========================================="

          # Step 1: Extract country boundary with tags from PBF
          echo "→ Step 1/5: Extracting boundary from PBF..."
          CODE_UPPER=$(echo "$ENTITY_CODE" | tr '[:lower:]' '[:upper:]')

          # Extract boundary using ogr2ogr with SQL WHERE clause (supports AND logic)
          # OSM stores tags in 'other_tags' as hstore format: "key"=>"value"
          # Filters ordered by selectivity: ISO code (most selective) → admin_level → boundary (least selective)
          if ! ogr2ogr -f GeoJSON "$TMPDIR/${ENTITY_CODE}_raw.geojson" "$PLANET_PBF" multipolygons \
            -sql "SELECT * FROM multipolygons WHERE other_tags LIKE '%\"ISO3166-1:alpha2\"=>\"$CODE_UPPER\"%' AND admin_level='2' AND boundary='administrative'" -q; then
            echo "❌ Failed to extract and convert boundary from PBF" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to extract and convert boundary from PBF" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 1
          fi

          # Extract name from properties
          NAME_EN=$(jq -r '.features[0].properties["name:en"] // .features[0].properties.name // "'"$ENTITY_NAME"'"' "$TMPDIR/${ENTITY_CODE}_raw.geojson")
          echo "  ✓ Extracted boundary: $NAME_EN (Code: $CODE_UPPER)"

          # Step 2: Clip with coastline if coastal entity
          HAS_COASTLINE="${{ inputs.has_coastline }}"

          if [ "$HAS_COASTLINE" = "true" ]; then
            echo "→ Step 2/5: Clipping with coastline data..."
            if ogr2ogr -f GeoJSON "$TMPDIR/${ENTITY_CODE}_clipped.geojson" "$COASTLINE_DB" land_polygons \
              -clipsrc "$TMPDIR/${ENTITY_CODE}_raw.geojson" -q 2>/dev/null; then
              echo "  ✓ Clipped with coastline data"
              WORKING_FILE="$TMPDIR/${ENTITY_CODE}_clipped.geojson"
            else
              echo "  ⚠️ Coastline clipping failed, using raw boundary"
              WORKING_FILE="$TMPDIR/${ENTITY_CODE}_raw.geojson"
            fi
          else
            echo "→ Step 2/5: Skipping coastline clipping (landlocked)"
            WORKING_FILE="$TMPDIR/${ENTITY_CODE}_raw.geojson"
          fi

          # Step 3: Dissolve and simplify geometry
          echo "→ Step 3/5: Dissolving geometry..."
          if ! ogr2ogr -f GeoJSON "$TMPDIR/${ENTITY_CODE}_dissolved.geojson" "$WORKING_FILE" -dialect sqlite \
            -sql "SELECT ST_CollectionExtract(ST_UnaryUnion(ST_Collect(geometry)), 3) AS geometry FROM OGRGeoJSON" -q; then
            echo "❌ Failed to dissolve geometry" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to dissolve geometry" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 3
          fi
          echo "  ✓ Dissolved geometry"

          # Step 4: Compute area using Python script
          echo "→ Step 4/5: Computing area in km²..."
          COMPUTED_AREA=$(python3 scripts/compute_area.py "$TMPDIR/${ENTITY_CODE}_dissolved.geojson" 2>&1)
          if [ $? -eq 0 ]; then
            echo "  ✓ Computed area: ${COMPUTED_AREA} km²"
          else
            echo "❌ Failed to compute area: $COMPUTED_AREA" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to compute area" >> $GITHUB_OUTPUT
            rm -rf "$TMPDIR"
            exit 4
          fi

          # Step 5: Create final GeoJSON with only essential properties
          echo "→ Step 5/5: Creating final output..."
          jq --arg name "$NAME_EN" --arg code "$CODE_UPPER" --arg area "$COMPUTED_AREA" \
            '.features[0].properties = {"name:en": $name, "code": $code, "area": ($area | tonumber)}' \
            "$TMPDIR/${ENTITY_CODE}_dissolved.geojson" > "$OUTPUT_DIR/$OUTPUT_FILE"
          echo "  ✓ Created final output"

          # Clean up temp files
          rm -rf "$TMPDIR"

          # Validate the output has features
          FEATURE_COUNT=$(jq '.features | length' "$OUTPUT_DIR/$OUTPUT_FILE" 2>/dev/null || echo "0")

          if [ "$FEATURE_COUNT" -eq 0 ]; then
            echo "❌ No features found in output" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=No features in output" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            exit 5
          fi

          echo "  ✓ Output validated: $FEATURE_COUNT feature(s), area: ${COMPUTED_AREA} km²"

          # Convert GeoJSON to GeoParquet
          echo "→ Converting to GeoParquet..."
          PARQUET_FILE="${OUTPUT_DIR}/${ENTITY_CODE}.boundary.parquet"
          if ! ogr2ogr -f Parquet "$PARQUET_FILE" "$OUTPUT_DIR/$OUTPUT_FILE" \
            --config OGR_GEOJSON_MAX_OBJ_SIZE 0 \
            -lco COMPRESSION=ZSTD \
            -lco GEOMETRY_ENCODING=GEOARROW \
            -lco ROW_GROUP_SIZE=65536; then
            echo "❌ Failed to convert to GeoParquet" >&2
            echo "success=false" >> $GITHUB_OUTPUT
            echo "failure_reason=Failed to convert to GeoParquet" >> $GITHUB_OUTPUT
            rm -f "$OUTPUT_DIR/$OUTPUT_FILE"
            exit 8
          fi
          echo "  ✓ GeoParquet created: $(basename $PARQUET_FILE)"

          # Set outputs
          echo "success=true" >> $GITHUB_OUTPUT
          echo "output_file=$OUTPUT_DIR/$OUTPUT_FILE" >> $GITHUB_OUTPUT
          echo "parquet_file=$PARQUET_FILE" >> $GITHUB_OUTPUT
          echo "feature_count=$FEATURE_COUNT" >> $GITHUB_OUTPUT

          echo "✅ $OUTPUT_FILE created successfully with $FEATURE_COUNT feature(s)"
          if [ "$AREA_KM2" != "N/A" ] && [ "$AREA_KM2" != "null" ]; then
            echo "   Area: ${AREA_KM2} km²"
          fi
          echo "✅ $(basename $PARQUET_FILE) created successfully"
          echo "Finished at: $(date -u +%Y-%m-%d_%H:%M:%S)"

      - name: Create metadata
        if: steps.extract.outputs.success == 'true'
        uses: openplanetdata/actions/create-metadata@main
        with:
          file: ${{ steps.extract.outputs.output_file }}
          remote_filename: ${{ inputs.entity_code }}.boundary.geojson
          remote_path: ${{ inputs.remote_path }}
          remote_version: ${{ inputs.remote_version }}
          tags: ${{ inputs.tags }}

      - name: Upload to R2
        if: steps.extract.outputs.success == 'true'
        uses: openplanetdata/actions/upload@main
        env:
          RCLONE_CONFIG_DATA: ${{ secrets.RCLONE_CONFIG_DATA }}
        with:
          file: ${{ steps.extract.outputs.output_file }}
          remote_filename: ${{ inputs.entity_code }}.boundary.geojson
          remote_path: ${{ inputs.remote_path }}
          remote_version: ${{ inputs.remote_version }}

      - name: Create metadata for Parquet
        if: steps.extract.outputs.success == 'true'
        uses: openplanetdata/actions/create-metadata@main
        with:
          file: ${{ steps.extract.outputs.parquet_file }}
          remote_filename: ${{ inputs.entity_code }}.boundary.parquet
          remote_path: ${{ inputs.remote_path }}
          remote_version: ${{ inputs.remote_version }}
          tags: ${{ inputs.tags }}

      - name: Upload Parquet to R2
        if: steps.extract.outputs.success == 'true'
        uses: openplanetdata/actions/upload@main
        env:
          RCLONE_CONFIG_DATA: ${{ secrets.RCLONE_CONFIG_DATA }}
        with:
          file: ${{ steps.extract.outputs.parquet_file }}
          remote_filename: ${{ inputs.entity_code }}.boundary.parquet
          remote_path: ${{ inputs.remote_path }}
          remote_version: ${{ inputs.remote_version }}

      - name: Cleanup generated files
        if: always()
        run: |
          # Always cleanup metadata and temp files
          rm -f boundaries/${{ inputs.entity_type }}s/*.boundary.geojson.{sha256,metadata}
          rm -f boundaries/${{ inputs.entity_type }}s/*.boundary.parquet.{sha256,metadata}
          rm -rf boundaries/tmp boundaries/logs

      - name: Cleanup planet files
        if: always() && inputs.cleanup_planet_files == true
        run: |
          echo "Cleaning up planet files..."
          rm -f planet-*.osm.pbf coastline-*.gpkg
